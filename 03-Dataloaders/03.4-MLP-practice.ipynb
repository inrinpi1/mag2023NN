{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4609160-6159-4abd-80fe-140778e7a32c",
   "metadata": {},
   "source": [
    "Потренируемся самостоятельно писать многослойный перцептрон для работы с текстами. \n",
    "\n",
    "Возьмем для этого датасет про юридические тексты. В этом датасете есть описания дел, а в качестве цп - то, что с делами произошло."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5607f6-9239-4ccc-8086-228bf8a6a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/rsuh-python/mag2022/main/CL/term02/06-Embeddings/legal_text_classification.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc52864-6580-46c9-8468-890cde808db7",
   "metadata": {},
   "source": [
    "Для начала напишем бейзлайн - логистическую регрессию. Возьмем в качестве признаков только текст - описание самого дела (case_text). Целевую переменную, очевидно, нужно превратить в чиселки (OHE). \n",
    "\n",
    "- проверьте данные на пропуски\n",
    "- проверьте баланс классов - это очень важно!\n",
    "- используйте TF-IDF\n",
    "- не забудьте использовать LabelEncoder\n",
    "- логистической регрессии может понадобиться выставить solver='liblinear'\n",
    "- если не помните, как работать с несбалансированными датасетами, просмотрите наши конспекты - точно где-то было (на худой конец документация к логрегу)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c8ccc-7ded-43d2-bc46-d5445f3d1fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c80c1b-ac2b-449a-9868-cc41506db78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('legal_text_classification.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c6bae-85ec-4871-adbf-54f7cc141bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3364ccf2-85f6-406b-87c0-f6a90a3b6d99",
   "metadata": {},
   "source": [
    "Если все сделали как я, должна получиться средняя f-score в районе 0.5. \n",
    "\n",
    "Теперь давайте попробуем написать нейронную сетку по аналогии с тетрадкой про твиттер из прошлого семинара. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b24c8-4ae7-4cd5-a156-1dad06d2f782",
   "metadata": {
    "id": "CgiT9Xow1sd5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155be6a9-d883-4fc0-b525-6308334f1865",
   "metadata": {},
   "source": [
    "class_weight - очень полезная для нас штука. Можно вычислить веса классов автоматически с ее помощью:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ad2f6-cabe-4b47-b2aa-dfa4f48546fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# первый аргумент - какие веса высчитывать, второй - какие у нас классы, третий - какие их частоты\n",
    "yweights = class_weight.compute_class_weight('balanced', classes=np.unique(data.case_outcome), y=data.case_outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6245dfdc-d3c5-4029-b246-5d5298ffe072",
   "metadata": {},
   "source": [
    "Заметьте, что возвращает оно np.array. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dce92e0-7af0-489d-b6e9-c4429e3bf960",
   "metadata": {},
   "source": [
    "Нужно написать:\n",
    "\n",
    "- функцию для предобработки текста, которая получает сырой текст и возвращает список токенов\n",
    "- создать словарь word2id\n",
    "- и обратный ему id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921845b-2713-464b-a677-8da6ae945c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52c8121-fd8c-4945-b82a-12ee54f067f8",
   "metadata": {},
   "source": [
    "Лучше это все, конечно, запускать в колабе... не забудьте там выбрать T4 GPU в рантайме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec37b61-b5d3-4f47-8835-7c9df63676a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YrzM7MnCQeP_",
    "outputId": "fdd46d22-8f06-48eb-cddf-bec4393de4b4"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6159ef9-87c3-46b4-bb51-c0b4160a53c4",
   "metadata": {},
   "source": [
    "Нужно написать класс для нашего датасета (можно беспощадно копипастить из тетрадки про твиттер)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca8e2d0-e4e1-4145-be1e-e30f1b539769",
   "metadata": {
    "id": "FMs4ZohJ1seI"
   },
   "outputs": [],
   "source": [
    "class LegalDataset(Dataset):\n",
    "\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6981fdca-fbc0-4df0-89eb-151c8c4cd631",
   "metadata": {
    "id": "8Zl4FxB71seI"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "train_iterator = DataLoader(train_dataset, collate_fn = train_dataset.collate_fn, sampler=train_sampler, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff657fc-d2a5-4b85-961e-b385d8171dda",
   "metadata": {
    "id": "ZR_upb-_1seJ"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "val_iterator = DataLoader(val_dataset, collate_fn=val_dataset.collate_fn, sampler=val_sampler, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2221a2-d551-4d89-9e71-01e96188e7ae",
   "metadata": {},
   "source": [
    "Ну и наконец напишем архитектуру. Модель при инициализации должна принимать размер словаря и эмбеддинга. У нас в датасете 10 классов, поэтому, в отличие от тетрадки про твиттер, нужно использовать Softmax и возвращать вероятности классов. В качестве лосса подойдет кросс-энтропия (я ее уже за вас вписала вместе с весами классов). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab1e4b-ab21-4801-ab6a-9ca492eea1aa",
   "metadata": {
    "id": "NdV7oSIc1seK"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "   # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e291f6f8-549a-4f2c-ad61-6af62505ea92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFQ-WEY4cxkv",
    "outputId": "e2db59e9-fcf6-4344-f653-3cbee0ccad5e"
   },
   "outputs": [],
   "source": [
    "batch, y = next(iter(train_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6e107-23f7-4c46-ae0c-0b9b603cd40a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHc9E_96dJBH",
    "outputId": "f55a5850-b7ad-480d-98d4-19c4cada56d7"
   },
   "outputs": [],
   "source": [
    "#пропустим через модель наш первый батч, чтобы проверить, что все работает\n",
    "model = MLP(len(id2word), 5)\n",
    "output = torch.argmax(model(batch), dim=1) # argmax из вероятностей сделает классы\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4e925a-7fa2-4cef-81ed-d2f729b2680f",
   "metadata": {},
   "source": [
    "Теперь нужно написать трейнлуп (лучше скопипастить откуда-нибудь), инициализировать нашу модель и запустить)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de7ee36-3c08-4aa5-8d30-ec01a85b2a33",
   "metadata": {
    "id": "WO35IZES1seL"
   },
   "outputs": [],
   "source": [
    "def train_loop():\n",
    "    #your code here\n",
    "\n",
    "model = MLP(len(word2id), 5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(weight=yweights)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)\n",
    "\n",
    "train_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7a0f8a-6104-425f-ac98-0ff48fdc6271",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "boMAjlVM1seM",
    "outputId": "e9d98c33-e928-4207-d499-67d1c1dea227"
   },
   "source": [
    "Скорее всего, вам понадобится учиться очень много эпох, чтобы предсказывать что-нибудь стоящее (эпох 100...), и, вероятнее всего, придется играться с архитектурой, чтобы получить приличное качество. На семинаре на эксперименты времени нет, поэтому добаловаться можно дома - и заодно попробовать подключить эмбеддинги w2v, например. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04afb79-453d-49d3-ac01-1e7bab9f2687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlearn",
   "language": "python",
   "name": "mlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
